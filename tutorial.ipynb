{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a tutorial, with accompanying slides.  We will develop a kind of _minimal working example_ of running an experiment with neural networks, inspired by work in natural language semantics.  Instructions for using this notebook may be found at https://github.com/shanest/nn-tutorial.  The slides also contain pointers to more advanced topics and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we will conduct a very miniature version of one of the experiments in [Steinert-Threlkeld and Szymanik, \"Learnability and Semantic Universals\"](https://semanticsarchive.net/Archive/mQ2Y2Y2Z/LearnabilitySemanticUniversals.pdf).  In the figure below, they compare a monotone quantifier (_at least 4_) to a non-monotone one (_at least 6 or at most 2_), showing that the former is learned faster than the latter.  We will look at a similar pair of quantifiers here.\n",
    "\n",
    "![](imgs/exp1a_acc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There are several important differences between what we will do today and what's done in the paper.  Because of time constraints, we won't do multiple trials or statistical analysis thereof, and we won't be using recurrent networks.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized quantifier theory provides the meanings for expressions like \"most\", \"all\", \"between 5 and 10\", etc. as they are used in sentences like\n",
    "\n",
    "(1) Most of the students are happy.\n",
    "\n",
    "(1) is true just in case the set of students who are happy outnumbers the set of students who are not happy.  Using interpretation bracket notation, where $\\mathcal{M}$ is a model:\n",
    "\n",
    "$$ [[ (1) ]]^{\\mathcal{M}} = 1 \\text{ iff } \\textsf{card}([[\\text{students}]] \\cap [[\\text{happy}]]) > \\textsf{card}([[\\text{students} \\setminus \\text{happy}]]) $$\n",
    "\n",
    "We can view the meaning of an expression like \"most\" as a function, which takes as input models of the form $\\mathcal{M} = \\langle M, A, B \\rangle$, where $A$ is the denotation of the restrictor (e.g. \"students\") and $B$ that of the nuclear scope (e.g. \"are happy\") and outputs a 1 or 0 based on the condition above.  \n",
    "\n",
    "In other words, a quantifier is a _classifier_ of models, classifying every model as 1 (True) or 0 (False)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a neural network classifier and train it to _learn_ different quantifiers.  Our goal will be to qualitatively compare _monotone_ (e.g. \"most\") to _non-monotone_ (e.g. \"between 5 and 10\") quantifiers.  Please refer to the paper linked above for full definitions of these concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model_size': 16,  # how big our models will be\n",
    "    'num_epochs': 2,  # one epoch = one loop through the dataset\n",
    "    'batch_size': 32,  # size of one batch of training examples\n",
    "    'eval_every': 20,  # frequency of evaluations, in # of batches\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_models(length):\n",
    "    return np.array(list(\n",
    "        itertools.product([0, 1], repeat=length)\n",
    "    ))\n",
    "\n",
    "get_all_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most(model):\n",
    "    return int(sum(model) > 0.5*len(model))  # integers are useful later\n",
    "\n",
    "def between_m_n(model, m, n):\n",
    "    return int(m < sum(model) < n)\n",
    "\n",
    "def batch_apply(models, quantifier):\n",
    "    \"\"\"Applies quantifier function to 2-D array of models,\n",
    "    where each row corresponds to one model.\"\"\"\n",
    "    return np.apply_along_axis(quantifier, 1, models)\n",
    "\n",
    "batch_apply(get_all_models(3), most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(models, labels):\n",
    "    \"\"\"Shuffles the order of an array of models and of labels.\"\"\"\n",
    "    assert len(models) == len(labels), \"models and labels must be of same length\"\n",
    "    permutation = np.random.permutation(len(models))\n",
    "    return models[permutation], labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(model_size, quantifier, train_split=0.7, shuffle=True):\n",
    "    \"\"\"Gets training and test data for quantifier.\"\"\"\n",
    "    # get all models and labels\n",
    "    models = get_all_models(model_size)\n",
    "    labels = batch_apply(models, quantifier)\n",
    "    # shuffle them\n",
    "    if shuffle:\n",
    "        models, labels = shuffle_data(models, labels)\n",
    "    # split into train/test\n",
    "    split_index = int(len(models) * train_split)  # int returns floor / rounds down\n",
    "    train_models = models[:split_index]  # up to index, not including\n",
    "    train_labels = labels[:split_index]\n",
    "    test_models = models[split_index:]  # from index, including\n",
    "    test_labels = labels[split_index:]\n",
    "    return train_models, train_labels, test_models, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([39203, 26333]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(batch_apply(get_all_models(16), lambda model: int(sum(model) >= 9)), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 0],\n",
       "        [0, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0]]), array([1, 0, 1, 0, 0]), array([[0, 1, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 1]]), array([1, 0, 1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(3, most)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):  # all models in PyTorch extend nn.Module\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FFNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, 32)  # first hidden layer has 32 units\n",
    "        self.layer2 = nn.Linear(32, 32)  # as does second\n",
    "        self.output = nn.Linear(32, output_size)\n",
    "        \n",
    "    def forward(self, models):  # note: forward can take any number of arguments\n",
    "        x = torch.as_tensor(models, dtype=torch.float)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.output(x)\n",
    "        return F.softmax(x, dim=1)  # softmax converts to a probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "train_models, train_labels, test_models, test_labels = get_data(\n",
    "    params['model_size'],\n",
    "    most\n",
    ")\n",
    "    \n",
    "# get the model\n",
    "model = FFNN(params['model_size'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNN(\n",
       "  (layer1): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (layer2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5144, 0.4856],\n",
       "        [0.5078, 0.4922],\n",
       "        [0.4985, 0.5015],\n",
       "        ...,\n",
       "        [0.5012, 0.4988],\n",
       "        [0.4858, 0.5142],\n",
       "        [0.4892, 0.5108]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# * install pandas, plotnine\n",
    "# * record data, plot learning curves\n",
    "\n",
    "def train(params, quantifier):\n",
    "    # get the data\n",
    "    train_models, train_labels, test_models, test_labels = get_data(\n",
    "        params['model_size'],\n",
    "        quantifier\n",
    "    )\n",
    "    \n",
    "    # get the model\n",
    "    model = FFNN(params['model_size'], 2)  # 2 outputs: False/True\n",
    "    \n",
    "    # get an optimizer\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    num_batches = int(len(train_models) / params['batch_size'])\n",
    "\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        # shuffle the training data each epoch\n",
    "        train_models, train_labels = shuffle_data(train_models, train_labels)\n",
    "        model.train()  # for our model, this has no effect, but is good practice\n",
    "\n",
    "        # individual training steps!\n",
    "        for batch_num in range(num_batches):\n",
    "            # batch the data\n",
    "            batch_models = train_models[batch_num*params['batch_size']:(batch_num+1)*params['batch_size']]\n",
    "            batch_labels = train_labels[batch_num*params['batch_size']:(batch_num+1)*params['batch_size']]\n",
    "\n",
    "            # get model's output\n",
    "            model_probs = model(batch_models)  # calls .forward\n",
    "\n",
    "            # zero the gradients\n",
    "            opt.zero_grad()\n",
    "            # calculate loss\n",
    "            loss = F.cross_entropy(model_probs,\n",
    "                                   torch.as_tensor(batch_labels))\n",
    "            loss.backward()  # computes the gradients!\n",
    "            opt.step()  # updates the parameters\n",
    "\n",
    "            if (batch_num + 1) % params['eval_every'] == 0:\n",
    "                with torch.no_grad():  # speeds things up\n",
    "                    model.eval()  # again, no effect on our model, but good practice\n",
    "                    model_probs = model(test_models).numpy()\n",
    "                    model_predictions = model_probs.argmax(axis=1).flatten()\n",
    "                    # 1 if correct prediction, 0 otherwise\n",
    "                    correct = (model_predictions == test_labels).astype(int)\n",
    "                    print('Test set accuracy; after epoch {}, batch {}: {}'.format(\n",
    "                        epoch, batch_num+1,\n",
    "                        sum(correct) / len(correct)\n",
    "                    ))\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy; after epoch 0, batch 20: 0.5966634453995219\n",
      "Test set accuracy; after epoch 0, batch 40: 0.5962565484970246\n",
      "Test set accuracy; after epoch 0, batch 60: 0.5962565484970246\n",
      "Test set accuracy; after epoch 0, batch 80: 0.5965617211738976\n",
      "Test set accuracy; after epoch 0, batch 100: 0.6533238390722751\n",
      "Test set accuracy; after epoch 0, batch 120: 0.6863842124001831\n",
      "Test set accuracy; after epoch 0, batch 140: 0.7784954987030162\n",
      "Test set accuracy; after epoch 0, batch 160: 0.8446671074716444\n",
      "Test set accuracy; after epoch 0, batch 180: 0.8711154061339708\n",
      "Test set accuracy; after epoch 0, batch 200: 0.8579421189156198\n",
      "Test set accuracy; after epoch 0, batch 220: 0.901480087482834\n",
      "Test set accuracy; after epoch 0, batch 240: 0.8985809470525405\n",
      "Test set accuracy; after epoch 0, batch 260: 0.9206042419002085\n",
      "Test set accuracy; after epoch 0, batch 280: 0.9328111489751284\n",
      "Test set accuracy; after epoch 0, batch 300: 0.9409999491378872\n",
      "Test set accuracy; after epoch 0, batch 320: 0.9438990895681807\n",
      "Test set accuracy; after epoch 0, batch 340: 0.9423732261838157\n",
      "Test set accuracy; after epoch 0, batch 360: 0.9410508112506993\n",
      "Test set accuracy; after epoch 0, batch 380: 0.9472559890137836\n",
      "Test set accuracy; after epoch 0, batch 400: 0.9592594476374549\n",
      "Test set accuracy; after epoch 0, batch 420: 0.96266720919587\n",
      "Test set accuracy; after epoch 0, batch 440: 0.9435430547784955\n",
      "Test set accuracy; after epoch 0, batch 460: 0.9634301408880525\n",
      "Test set accuracy; after epoch 0, batch 480: 0.9709577335842531\n",
      "Test set accuracy; after epoch 0, batch 500: 0.9708560093586287\n",
      "Test set accuracy; after epoch 0, batch 520: 0.9771629113473373\n",
      "Test set accuracy; after epoch 0, batch 540: 0.9799603275520065\n",
      "Test set accuracy; after epoch 0, batch 560: 0.9762473933167184\n",
      "Test set accuracy; after epoch 0, batch 580: 0.9463404709831646\n",
      "Test set accuracy; after epoch 0, batch 600: 0.9826051574182392\n",
      "Test set accuracy; after epoch 0, batch 620: 0.9852499872844718\n",
      "Test set accuracy; after epoch 0, batch 640: 0.9868267127816489\n",
      "Test set accuracy; after epoch 0, batch 660: 0.9907939575809979\n",
      "Test set accuracy; after epoch 0, batch 680: 0.9908448196938101\n",
      "Test set accuracy; after epoch 0, batch 700: 0.9864198158791516\n",
      "Test set accuracy; after epoch 0, batch 720: 0.9868775748944612\n",
      "Test set accuracy; after epoch 0, batch 740: 0.9866741264432124\n",
      "Test set accuracy; after epoch 0, batch 760: 0.9921163725141142\n",
      "Test set accuracy; after epoch 0, batch 780: 0.9958293067494024\n",
      "Test set accuracy; after epoch 0, batch 800: 0.9948629266059712\n",
      "Test set accuracy; after epoch 0, batch 820: 0.996643100554397\n",
      "Test set accuracy; after epoch 0, batch 840: 0.9925232694166116\n",
      "Test set accuracy; after epoch 0, batch 860: 0.9977112049234526\n",
      "Test set accuracy; after epoch 0, batch 880: 0.9938965464625401\n",
      "Test set accuracy; after epoch 0, batch 900: 0.9974568943593917\n",
      "Test set accuracy; after epoch 0, batch 920: 0.99694827323127\n",
      "Test set accuracy; after epoch 0, batch 940: 0.9970499974568944\n",
      "Test set accuracy; after epoch 0, batch 960: 0.9984232745028229\n",
      "Test set accuracy; after epoch 0, batch 980: 0.9933370632216062\n",
      "Test set accuracy; after epoch 0, batch 1000: 0.9978637912618891\n",
      "Test set accuracy; after epoch 0, batch 1020: 0.9974568943593917\n",
      "Test set accuracy; after epoch 0, batch 1040: 0.999389654646254\n",
      "Test set accuracy; after epoch 0, batch 1060: 0.9983724123900107\n",
      "Test set accuracy; after epoch 0, batch 1080: 0.9988301714053202\n",
      "Test set accuracy; after epoch 0, batch 1100: 0.9992879304206297\n",
      "Test set accuracy; after epoch 0, batch 1120: 0.9994405167590662\n",
      "Test set accuracy; after epoch 0, batch 1140: 0.9989827577437567\n",
      "Test set accuracy; after epoch 0, batch 1160: 0.9994405167590662\n",
      "Test set accuracy; after epoch 0, batch 1180: 0.9979655154875133\n",
      "Test set accuracy; after epoch 0, batch 1200: 0.999694827323127\n",
      "Test set accuracy; after epoch 0, batch 1220: 0.998168963938762\n",
      "Test set accuracy; after epoch 0, batch 1240: 0.9996439652103148\n",
      "Test set accuracy; after epoch 0, batch 1260: 0.9997456894359392\n",
      "Test set accuracy; after epoch 0, batch 1280: 0.9997456894359392\n",
      "Test set accuracy; after epoch 0, batch 1300: 0.9997456894359392\n",
      "Test set accuracy; after epoch 0, batch 1320: 1.0\n",
      "Test set accuracy; after epoch 0, batch 1340: 0.9998982757743756\n",
      "Test set accuracy; after epoch 0, batch 1360: 0.9998474136615635\n",
      "Test set accuracy; after epoch 0, batch 1380: 0.999389654646254\n",
      "Test set accuracy; after epoch 0, batch 1400: 0.9997456894359392\n",
      "Test set accuracy; after epoch 0, batch 1420: 0.999389654646254\n",
      "Test set accuracy; after epoch 1, batch 20: 0.9998474136615635\n",
      "Test set accuracy; after epoch 1, batch 40: 1.0\n",
      "Test set accuracy; after epoch 1, batch 60: 0.9999491378871879\n",
      "Test set accuracy; after epoch 1, batch 80: 0.9999491378871879\n",
      "Test set accuracy; after epoch 1, batch 100: 0.9998982757743756\n",
      "Test set accuracy; after epoch 1, batch 120: 1.0\n",
      "Test set accuracy; after epoch 1, batch 140: 1.0\n",
      "Test set accuracy; after epoch 1, batch 160: 0.9991353440821932\n",
      "Test set accuracy; after epoch 1, batch 180: 0.9999491378871879\n",
      "Test set accuracy; after epoch 1, batch 200: 0.9999491378871879\n",
      "Test set accuracy; after epoch 1, batch 220: 0.9998982757743756\n",
      "Test set accuracy; after epoch 1, batch 240: 1.0\n",
      "Test set accuracy; after epoch 1, batch 260: 1.0\n",
      "Test set accuracy; after epoch 1, batch 280: 1.0\n",
      "Test set accuracy; after epoch 1, batch 300: 0.9999491378871879\n",
      "Test set accuracy; after epoch 1, batch 320: 1.0\n",
      "Test set accuracy; after epoch 1, batch 340: 1.0\n",
      "Test set accuracy; after epoch 1, batch 360: 1.0\n",
      "Test set accuracy; after epoch 1, batch 380: 1.0\n",
      "Test set accuracy; after epoch 1, batch 400: 1.0\n",
      "Test set accuracy; after epoch 1, batch 420: 1.0\n",
      "Test set accuracy; after epoch 1, batch 440: 0.9999491378871879\n",
      "Test set accuracy; after epoch 1, batch 460: 1.0\n",
      "Test set accuracy; after epoch 1, batch 480: 0.9999491378871879\n",
      "Test set accuracy; after epoch 1, batch 500: 1.0\n",
      "Test set accuracy; after epoch 1, batch 520: 1.0\n",
      "Test set accuracy; after epoch 1, batch 540: 1.0\n",
      "Test set accuracy; after epoch 1, batch 560: 1.0\n",
      "Test set accuracy; after epoch 1, batch 580: 1.0\n",
      "Test set accuracy; after epoch 1, batch 600: 1.0\n",
      "Test set accuracy; after epoch 1, batch 620: 1.0\n",
      "Test set accuracy; after epoch 1, batch 640: 1.0\n",
      "Test set accuracy; after epoch 1, batch 660: 1.0\n",
      "Test set accuracy; after epoch 1, batch 680: 1.0\n",
      "Test set accuracy; after epoch 1, batch 700: 1.0\n",
      "Test set accuracy; after epoch 1, batch 720: 1.0\n",
      "Test set accuracy; after epoch 1, batch 740: 1.0\n",
      "Test set accuracy; after epoch 1, batch 760: 1.0\n",
      "Test set accuracy; after epoch 1, batch 780: 1.0\n",
      "Test set accuracy; after epoch 1, batch 800: 1.0\n",
      "Test set accuracy; after epoch 1, batch 820: 1.0\n",
      "Test set accuracy; after epoch 1, batch 840: 1.0\n",
      "Test set accuracy; after epoch 1, batch 860: 1.0\n",
      "Test set accuracy; after epoch 1, batch 880: 1.0\n",
      "Test set accuracy; after epoch 1, batch 900: 1.0\n",
      "Test set accuracy; after epoch 1, batch 920: 1.0\n",
      "Test set accuracy; after epoch 1, batch 940: 1.0\n",
      "Test set accuracy; after epoch 1, batch 960: 1.0\n",
      "Test set accuracy; after epoch 1, batch 980: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1000: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1020: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1040: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1060: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1080: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1100: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1120: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1140: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1160: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1180: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1200: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1220: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1240: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1260: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1280: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1300: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1320: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1340: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1360: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1380: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1400: 1.0\n",
      "Test set accuracy; after epoch 1, batch 1420: 1.0\n"
     ]
    }
   ],
   "source": [
    "train(params, most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

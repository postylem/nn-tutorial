{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Neural Networks (with an application to quantifiers in natural language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a tutorial, with accompanying slides.  We will develop a kind of _minimal working example_ of running an experiment with neural networks, inspired by work in natural language semantics.  Instructions for using this notebook may be found at https://github.com/shanest/nn-tutorial.  The slides also contain pointers to more advanced topics and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we will conduct a very miniature version of one of the experiments in [Steinert-Threlkeld and Szymanik, \"Learnability and Semantic Universals\"](https://semanticsarchive.net/Archive/mQ2Y2Y2Z/LearnabilitySemanticUniversals.pdf).  In the figure below, they compare a monotone quantifier (_at least 4_) to a non-monotone one (_at least 6 or at most 2_), showing that the former is learned faster than the latter.  We will look at a similar pair of quantifiers here.\n",
    "\n",
    "![](imgs/exp1a_acc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There are several important differences between what we will do today and what's done in the paper.  Because of time constraints, we won't do multiple trials or statistical analysis thereof, and we won't be using recurrent networks.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized quantifier theory provides the meanings for expressions like \"most\", \"all\", \"between 5 and 10\", etc. as they are used in sentences like\n",
    "\n",
    "(1) Most of the students are happy.\n",
    "\n",
    "(1) is true just in case the set of students who are happy outnumbers the set of students who are not happy.  Using interpretation bracket notation, where $\\mathcal{M}$ is a model:\n",
    "\n",
    "$$ [[ (1) ]]^{\\mathcal{M}} = 1 \\text{ iff } \\textsf{card}([[\\text{students}]] \\cap [[\\text{happy}]]) > \\textsf{card}([[\\text{students} \\setminus \\text{happy}]]) $$\n",
    "\n",
    "We can view the meaning of an expression like \"most\" as a function, which takes as input models of the form $\\mathcal{M} = \\langle M, A, B \\rangle$, where $A$ is the denotation of the restrictor (e.g. \"students\") and $B$ that of the nuclear scope (e.g. \"are happy\") and outputs a 1 or 0 based on the condition above.  \n",
    "\n",
    "In other words, a quantifier is a _classifier_ of models, classifying every model as 1 (True) or 0 (False)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a neural network classifier and train it to _learn_ different quantifiers.  Our goal will be to qualitatively compare _monotone_ (e.g. \"most\") to _non-monotone_ (e.g. \"between 5 and 10\") quantifiers.  Please refer to the paper linked above for full definitions of these concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Input\n",
    "\n",
    "We need a way of passing models into a neural network.  To do this, they must be represented as vectors of real numbers.  We will do this in the following way.\n",
    "\n",
    "For convenience, we will assume properties known as Extensionality (EXT) and Conservativity (CONS) (see SEP for these definitions).  Together, these say that only the sets $A \\cap B$ and $A \\ B$ are relevant to the truth of a quantifier.  We can thus represent a model $\\mathcal{M}$ by encoding whether each object in $M$ belongs to $A \\cap B$ (in which case we will call it a $1$) or to $A \\setminus B$ (in which case we will call it a $0$).\n",
    "\n",
    "Thus, every model of size $n$ can be encoded as an $n$-dimensional vector of bits.  Conversely, every $n$-bit vector corresponds to a model $\\mathcal{M}$.  (Subtle caveat: this correspondence requires an enumeration of $M$.  See the above paper for discussion.)\n",
    "\n",
    "So we will consider models of a fixed size $N$, and feed our networks $N$-bit vectors.  It will output its guess as to whether the quantifier is true or false for that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model_size': 16,  # how big our models will be\n",
    "    'num_epochs': 2,  # one epoch = one loop through the dataset\n",
    "    'batch_size': 32,  # size of one batch of training examples\n",
    "    'eval_every': 20,  # frequency of evaluations, in # of batches\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you will in general have more parameters when you do your experiments, and will usually want to pass these in to your program as command-line flags.  See [this repository]() for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can use the Python module `itertools` to quickly generate all models of a certain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_models(length):\n",
    "    \"\"\"Returns a 2-D numpy array containing as rows all bit sequences of the specified length.\"\"\"\n",
    "    return np.array(list(\n",
    "        itertools.product([0, 1], repeat=length)\n",
    "    ))\n",
    "\n",
    "get_all_models(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our quantifiers will be functions from bit-arrays to truth values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most(model):\n",
    "    return int(sum(model) > 0.5*len(model))  # integers are useful later\n",
    "\n",
    "def between_m_n(model, m, n):\n",
    "    return int(m < sum(model) < n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` provides a nice method `apply_along_axis` that we can use to apply a quantifier to the array of all models generated by `get_all_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_apply(models, quantifier):\n",
    "    \"\"\"Applies quantifier function to 2-D array of models,\n",
    "    where each row corresponds to one model.\"\"\"\n",
    "    return np.apply_along_axis(quantifier, 1, models)\n",
    "\n",
    "batch_apply(get_all_models(3), most)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the order of data is very important.  This method applies the same shuffle to two sequences, intuitively the inputs and the outputs of a given function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(models, labels):\n",
    "    \"\"\"Shuffles the order of an array of models and of labels.\"\"\"\n",
    "    assert len(models) == len(labels), \"models and labels must be of same length\"\n",
    "    permutation = np.random.permutation(len(models))\n",
    "    return models[permutation], labels[permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put it all together: the method below takes in a model size and a quantifier function, and then generates the data, splits it into train/test sets (with a specified split percentage), shuffles it, and returns the two sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(model_size, quantifier, train_split=0.7, shuffle=True):\n",
    "    \"\"\"Gets training and test data for quantifier.\"\"\"\n",
    "    # get all models and labels\n",
    "    models = get_all_models(model_size)\n",
    "    labels = batch_apply(models, quantifier)\n",
    "    # shuffle them\n",
    "    if shuffle:\n",
    "        models, labels = shuffle_data(models, labels)\n",
    "    # split into train/test\n",
    "    split_index = int(len(models) * train_split)  # int returns floor / rounds down\n",
    "    train_models = models[:split_index]  # up to index, not including\n",
    "    train_labels = labels[:split_index]\n",
    "    test_models = models[split_index:]  # from index, including\n",
    "    test_labels = labels[split_index:]\n",
    "    return train_models, train_labels, test_models, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 1]]), array([0, 1, 0, 1, 0]), array([[1, 1, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 0]]), array([1, 1, 0]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(3, most)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [PyTorch](http://pytorch.org) library for building and training neural networks.  This library -- developed at FAIR (Facebook AI Research) -- provides a very nice mix of scaffolding and flexibility, as well as great integration with basic Python control flow, which allows for rapid development of your ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are always instances of new `class`es, which must always sub-class `nn.Module`.  By doing so, PyTorch will be able to automatically compute gradients for you, among other things.  \n",
    "\n",
    "Note the first line in `__init__`: this call to `super(...).__init__` is very important!\n",
    "\n",
    "The basic architecture of a model will be defined in the `__init__` method.  Here, we build a simple feed-forward network that has two hidden layers (`self.layer1` and `self.layer2`) and an output layer (`self.output`).\n",
    "\n",
    "The _forward pass_ of your model, i.e. the actual network computation, is then defined in the `forward` method.  Note our standard recipe: `x = F.relu(self.layer(x))`.  This encapsulates the non-linear transformation (`F.relu`) applied point-wise to a linear transformation of the inputs to a layer.\n",
    "\n",
    "Note that our `forward` method applies `softmax` at the output layer, to generate a probability distribution, as is common in classification tasks.\n",
    "\n",
    "Note that you `forward` is very flexible: you can define it with any number of arguments, and return anything you want (including tuples, non-`torch.Tensor` objects, and so on).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):  # all models in PyTorch extend nn.Module\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FFNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, 16)  # first hidden layer has 32 units\n",
    "        self.layer2 = nn.Linear(16, 16)  # as does second\n",
    "        self.output = nn.Linear(16, output_size)\n",
    "        \n",
    "    def forward(self, models):  # note: forward can take any number of arguments\n",
    "        x = torch.as_tensor(models, dtype=torch.float)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.output(x)\n",
    "        return F.softmax(x, dim=1)  # softmax converts to a probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining a complete training loop, let's just look at the model a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "train_models, train_labels, test_models, test_labels = get_data(\n",
    "    params['model_size'],\n",
    "    most\n",
    ")\n",
    "    \n",
    "# get the model\n",
    "model = FFNN(params['model_size'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the model gives a nice overview of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNN(\n",
       "  (layer1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (layer2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call `model` on some inputs, it calls `forward` on those inputs.  Note that we are sending a 2-D array here, with the first dimension being the number of example models, and the second dimension being the size of an individual model.  The output is a distribution over True/False for each example.\n",
    "\n",
    "(While we could have had only one output node, since $p(False) = 1 - p(True)$, it's useful to treat this as a two-way classification task, to be more in line with classification tasks with more than two classes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5423, 0.4577],\n",
       "        [0.5103, 0.4897],\n",
       "        [0.5437, 0.4563],\n",
       "        ...,\n",
       "        [0.5317, 0.4683],\n",
       "        [0.5388, 0.4612],\n",
       "        [0.5197, 0.4803]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the main training loop!  It's relatively straight-forward: get the training and test data, build the model, loop over epochs and mini-batches, performing one update for each mini-batch.\n",
    "\n",
    "The update works like this in PyTorch: you instantiate an `optimizer`, with the parameters of your model.  Each mini-batch, you call `zero_grad` on the optimizer, in order to clear out its previous gradient computation.  After computing the loss, you can then compute all the gradients of all the parameters in the model by `loss.backward()`.  Note that here `loss` can be any `torch.Tensor` object!  Then, you simply call `opt.step()` to update the parameters!\n",
    "\n",
    "We will also record some simple data during training so that we can visualize it.  This can also give you a feel for how you can store variables of interest while training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# * install pandas, plotnine\n",
    "# * record data, plot learning curves\n",
    "\n",
    "def train(params, quantifier):\n",
    "    \n",
    "    # get the data\n",
    "    train_models, train_labels, test_models, test_labels = get_data(\n",
    "        params['model_size'],\n",
    "        quantifier\n",
    "    )\n",
    "    \n",
    "    # get the model\n",
    "    model = FFNN(params['model_size'], 2)  # 2 outputs: False/True\n",
    "    \n",
    "    # get an optimizer\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    num_batches = int(len(train_models) / params['batch_size'])\n",
    "\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        # shuffle the training data each epoch\n",
    "        train_models, train_labels = shuffle_data(train_models, train_labels)\n",
    "        model.train()  # for our model, this has no effect, but is good practice\n",
    "\n",
    "        # individual training steps!\n",
    "        for batch_idx in range(num_batches):\n",
    "            # batch the data\n",
    "            batch_models = train_models[batch_idx*params['batch_size']:(batch_idx+1)*params['batch_size']]\n",
    "            batch_labels = train_labels[batch_idx*params['batch_size']:(batch_idx+1)*params['batch_size']]\n",
    "\n",
    "            # get model's output\n",
    "            model_probs = model(batch_models)  # calls .forward\n",
    "\n",
    "            # zero the gradients\n",
    "            opt.zero_grad()\n",
    "            # calculate loss\n",
    "            loss = F.cross_entropy(model_probs,\n",
    "                                   torch.as_tensor(batch_labels))\n",
    "            loss.backward()  # computes the gradients!\n",
    "            opt.step()  # updates the parameters\n",
    "            \n",
    "            # get overall batch num for convenience\n",
    "            batch_num = epoch*num_batches + batch_idx + 1\n",
    "            if (batch_num + 1) % params['eval_every'] == 0:\n",
    "                with torch.no_grad():  # speeds things up\n",
    "                    model.eval()  # again, no effect on our model, but good practice\n",
    "                    model_probs = model(test_models).numpy()\n",
    "                    model_predictions = model_probs.argmax(axis=1).flatten()\n",
    "                    # 1 if correct prediction, 0 otherwise\n",
    "                    correct = (model_predictions == test_labels).astype(int)\n",
    "                    print('Test set accuracy, after batch {}: {}'.format(\n",
    "                        batch_num+1,\n",
    "                        sum(correct) / len(correct)\n",
    "                    ))\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy, after batch 20: 0.4038451757285998\n",
      "Test set accuracy, after batch 40: 0.46757540308224405\n",
      "Test set accuracy, after batch 60: 0.6821117949239611\n",
      "Test set accuracy, after batch 80: 0.6919790448095214\n",
      "Test set accuracy, after batch 100: 0.6635979858603326\n",
      "Test set accuracy, after batch 120: 0.7448247800213621\n",
      "Test set accuracy, after batch 140: 0.8170489802146381\n",
      "Test set accuracy, after batch 160: 0.7879558516860791\n",
      "Test set accuracy, after batch 180: 0.8368343420985708\n",
      "Test set accuracy, after batch 200: 0.8551955648237628\n",
      "Test set accuracy, after batch 220: 0.8679619551396165\n",
      "Test set accuracy, after batch 240: 0.8998524998728448\n",
      "Test set accuracy, after batch 260: 0.9196887238695896\n",
      "Test set accuracy, after batch 280: 0.937592187579472\n",
      "Test set accuracy, after batch 300: 0.947357713239408\n",
      "Test set accuracy, after batch 320: 0.9477137480290931\n",
      "Test set accuracy, after batch 340: 0.9659223844158487\n",
      "Test set accuracy, after batch 360: 0.9514775443771935\n",
      "Test set accuracy, after batch 380: 0.9724835969686181\n",
      "Test set accuracy, after batch 400: 0.9745180814811047\n",
      "Test set accuracy, after batch 420: 0.9815370530491837\n",
      "Test set accuracy, after batch 440: 0.958699964396521\n",
      "Test set accuracy, after batch 460: 0.9769086007832766\n",
      "Test set accuracy, after batch 480: 0.9829611922079243\n",
      "Test set accuracy, after batch 500: 0.9365240832104166\n",
      "Test set accuracy, after batch 520: 0.9897767153247546\n",
      "Test set accuracy, after batch 540: 0.9887086109556991\n",
      "Test set accuracy, after batch 560: 0.9916077513859926\n",
      "Test set accuracy, after batch 580: 0.9930827526575454\n",
      "Test set accuracy, after batch 600: 0.9952189613956564\n",
      "Test set accuracy, after batch 620: 0.9961344794262754\n",
      "Test set accuracy, after batch 640: 0.9962362036518997\n",
      "Test set accuracy, after batch 660: 0.9953206856212807\n",
      "Test set accuracy, after batch 680: 0.9918111998372412\n",
      "Test set accuracy, after batch 700: 0.9968465490056457\n",
      "Test set accuracy, after batch 720: 0.9944560297034739\n",
      "Test set accuracy, after batch 740: 0.9877930929250801\n",
      "Test set accuracy, after batch 760: 0.9979655154875133\n",
      "Test set accuracy, after batch 780: 0.998474136615635\n",
      "Test set accuracy, after batch 800: 0.9970499974568944\n",
      "Test set accuracy, after batch 820: 0.9988301714053202\n",
      "Test set accuracy, after batch 840: 0.9990336198565688\n",
      "Test set accuracy, after batch 860: 0.9984232745028229\n",
      "Test set accuracy, after batch 880: 0.9986267229540715\n",
      "Test set accuracy, after batch 900: 0.9994405167590662\n",
      "Test set accuracy, after batch 920: 0.9996439652103148\n",
      "Test set accuracy, after batch 940: 0.9998982757743756\n",
      "Test set accuracy, after batch 960: 0.9997456894359392\n",
      "Test set accuracy, after batch 980: 0.9997456894359392\n",
      "Test set accuracy, after batch 1000: 0.9998982757743756\n",
      "Test set accuracy, after batch 1020: 0.9998982757743756\n",
      "Test set accuracy, after batch 1040: 0.9997456894359392\n",
      "Test set accuracy, after batch 1060: 0.9996439652103148\n",
      "Test set accuracy, after batch 1080: 0.9998474136615635\n",
      "Test set accuracy, after batch 1100: 0.9997456894359392\n",
      "Test set accuracy, after batch 1120: 0.999389654646254\n",
      "Test set accuracy, after batch 1140: 0.9998982757743756\n",
      "Test set accuracy, after batch 1160: 0.9999491378871879\n",
      "Test set accuracy, after batch 1180: 0.9998474136615635\n",
      "Test set accuracy, after batch 1200: 0.9998982757743756\n",
      "Test set accuracy, after batch 1220: 0.9999491378871879\n",
      "Test set accuracy, after batch 1240: 0.9999491378871879\n",
      "Test set accuracy, after batch 1260: 0.9998982757743756\n",
      "Test set accuracy, after batch 1280: 0.9999491378871879\n",
      "Test set accuracy, after batch 1300: 0.9998474136615635\n",
      "Test set accuracy, after batch 1320: 0.999389654646254\n",
      "Test set accuracy, after batch 1340: 0.9999491378871879\n",
      "Test set accuracy, after batch 1360: 0.9999491378871879\n",
      "Test set accuracy, after batch 1380: 0.9999491378871879\n",
      "Test set accuracy, after batch 1400: 0.9999491378871879\n",
      "Test set accuracy, after batch 1420: 0.9999491378871879\n",
      "Test set accuracy, after batch 1440: 0.9997965515487514\n",
      "Test set accuracy, after batch 1460: 0.9999491378871879\n",
      "Test set accuracy, after batch 1480: 0.9999491378871879\n",
      "Test set accuracy, after batch 1500: 0.9999491378871879\n",
      "Test set accuracy, after batch 1520: 1.0\n",
      "Test set accuracy, after batch 1540: 0.9999491378871879\n",
      "Test set accuracy, after batch 1560: 0.9999491378871879\n",
      "Test set accuracy, after batch 1580: 0.9999491378871879\n",
      "Test set accuracy, after batch 1600: 0.9999491378871879\n",
      "Test set accuracy, after batch 1620: 0.9999491378871879\n",
      "Test set accuracy, after batch 1640: 0.9999491378871879\n",
      "Test set accuracy, after batch 1660: 0.9999491378871879\n",
      "Test set accuracy, after batch 1680: 0.9999491378871879\n",
      "Test set accuracy, after batch 1700: 0.9999491378871879\n",
      "Test set accuracy, after batch 1720: 0.9999491378871879\n",
      "Test set accuracy, after batch 1740: 0.9999491378871879\n",
      "Test set accuracy, after batch 1760: 0.9999491378871879\n",
      "Test set accuracy, after batch 1780: 0.9999491378871879\n",
      "Test set accuracy, after batch 1800: 0.9999491378871879\n",
      "Test set accuracy, after batch 1820: 0.9999491378871879\n",
      "Test set accuracy, after batch 1840: 0.9999491378871879\n",
      "Test set accuracy, after batch 1860: 0.9999491378871879\n",
      "Test set accuracy, after batch 1880: 0.9999491378871879\n",
      "Test set accuracy, after batch 1900: 0.9999491378871879\n",
      "Test set accuracy, after batch 1920: 0.9999491378871879\n",
      "Test set accuracy, after batch 1940: 0.9999491378871879\n",
      "Test set accuracy, after batch 1960: 1.0\n",
      "Test set accuracy, after batch 1980: 0.9999491378871879\n",
      "Test set accuracy, after batch 2000: 1.0\n",
      "Test set accuracy, after batch 2020: 1.0\n",
      "Test set accuracy, after batch 2040: 0.9999491378871879\n",
      "Test set accuracy, after batch 2060: 1.0\n",
      "Test set accuracy, after batch 2080: 0.9999491378871879\n",
      "Test set accuracy, after batch 2100: 1.0\n",
      "Test set accuracy, after batch 2120: 1.0\n",
      "Test set accuracy, after batch 2140: 1.0\n",
      "Test set accuracy, after batch 2160: 1.0\n",
      "Test set accuracy, after batch 2180: 1.0\n",
      "Test set accuracy, after batch 2200: 1.0\n",
      "Test set accuracy, after batch 2220: 1.0\n",
      "Test set accuracy, after batch 2240: 0.9999491378871879\n",
      "Test set accuracy, after batch 2260: 0.9999491378871879\n",
      "Test set accuracy, after batch 2280: 1.0\n",
      "Test set accuracy, after batch 2300: 1.0\n",
      "Test set accuracy, after batch 2320: 1.0\n",
      "Test set accuracy, after batch 2340: 1.0\n",
      "Test set accuracy, after batch 2360: 1.0\n",
      "Test set accuracy, after batch 2380: 1.0\n",
      "Test set accuracy, after batch 2400: 1.0\n",
      "Test set accuracy, after batch 2420: 1.0\n",
      "Test set accuracy, after batch 2440: 1.0\n",
      "Test set accuracy, after batch 2460: 1.0\n",
      "Test set accuracy, after batch 2480: 1.0\n",
      "Test set accuracy, after batch 2500: 1.0\n",
      "Test set accuracy, after batch 2520: 1.0\n",
      "Test set accuracy, after batch 2540: 1.0\n",
      "Test set accuracy, after batch 2560: 1.0\n",
      "Test set accuracy, after batch 2580: 1.0\n",
      "Test set accuracy, after batch 2600: 1.0\n",
      "Test set accuracy, after batch 2620: 1.0\n",
      "Test set accuracy, after batch 2640: 1.0\n",
      "Test set accuracy, after batch 2660: 1.0\n",
      "Test set accuracy, after batch 2680: 1.0\n",
      "Test set accuracy, after batch 2700: 1.0\n",
      "Test set accuracy, after batch 2720: 1.0\n",
      "Test set accuracy, after batch 2740: 1.0\n",
      "Test set accuracy, after batch 2760: 1.0\n",
      "Test set accuracy, after batch 2780: 1.0\n",
      "Test set accuracy, after batch 2800: 1.0\n",
      "Test set accuracy, after batch 2820: 1.0\n",
      "Test set accuracy, after batch 2840: 1.0\n",
      "Test set accuracy, after batch 2860: 1.0\n"
     ]
    }
   ],
   "source": [
    "train(params, most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy, after batch 20: 0.5017547428920197\n",
      "Test set accuracy, after batch 40: 0.5017547428920197\n",
      "Test set accuracy, after batch 60: 0.5017547428920197\n",
      "Test set accuracy, after batch 80: 0.5017547428920197\n",
      "Test set accuracy, after batch 100: 0.5017547428920197\n",
      "Test set accuracy, after batch 120: 0.5017547428920197\n",
      "Test set accuracy, after batch 140: 0.5017547428920197\n",
      "Test set accuracy, after batch 160: 0.49738060119017347\n",
      "Test set accuracy, after batch 180: 0.48634352270993336\n",
      "Test set accuracy, after batch 200: 0.5046538833223132\n",
      "Test set accuracy, after batch 220: 0.4991099130257871\n",
      "Test set accuracy, after batch 240: 0.48837800722242003\n",
      "Test set accuracy, after batch 260: 0.5799298102843192\n",
      "Test set accuracy, after batch 280: 0.569452215045013\n",
      "Test set accuracy, after batch 300: 0.5827272264889883\n",
      "Test set accuracy, after batch 320: 0.6956919790448095\n",
      "Test set accuracy, after batch 340: 0.7198006205177763\n",
      "Test set accuracy, after batch 360: 0.8087075937134428\n",
      "Test set accuracy, after batch 380: 0.705610091043182\n",
      "Test set accuracy, after batch 400: 0.8116067341437363\n",
      "Test set accuracy, after batch 420: 0.8361731346320126\n",
      "Test set accuracy, after batch 440: 0.7754946340470983\n",
      "Test set accuracy, after batch 460: 0.8090636285031281\n",
      "Test set accuracy, after batch 480: 0.8475662479019378\n",
      "Test set accuracy, after batch 500: 0.8526015970703423\n",
      "Test set accuracy, after batch 520: 0.8665378159808759\n",
      "Test set accuracy, after batch 540: 0.8606378108946645\n",
      "Test set accuracy, after batch 560: 0.8035196582066019\n",
      "Test set accuracy, after batch 580: 0.8441076242307105\n",
      "Test set accuracy, after batch 600: 0.8475153857891257\n",
      "Test set accuracy, after batch 620: 0.865062814709323\n",
      "Test set accuracy, after batch 640: 0.8260515741823915\n",
      "Test set accuracy, after batch 660: 0.8125222521743554\n",
      "Test set accuracy, after batch 680: 0.884644728142007\n",
      "Test set accuracy, after batch 700: 0.8715223030364682\n",
      "Test set accuracy, after batch 720: 0.8839326585626367\n",
      "Test set accuracy, after batch 740: 0.8857636946238747\n",
      "Test set accuracy, after batch 760: 0.9154671685061797\n",
      "Test set accuracy, after batch 780: 0.9163318244239865\n",
      "Test set accuracy, after batch 800: 0.9395758099791466\n",
      "Test set accuracy, after batch 820: 0.9361680484207314\n",
      "Test set accuracy, after batch 840: 0.9544275469202991\n",
      "Test set accuracy, after batch 860: 0.9547327195971721\n",
      "Test set accuracy, after batch 880: 0.9754335995117237\n",
      "Test set accuracy, after batch 900: 0.9703982503433193\n",
      "Test set accuracy, after batch 920: 0.980723259244189\n",
      "Test set accuracy, after batch 940: 0.9857077462997813\n",
      "Test set accuracy, after batch 960: 0.9879965413763288\n",
      "Test set accuracy, after batch 980: 0.9952698235084685\n",
      "Test set accuracy, after batch 1000: 0.9809267076954377\n",
      "Test set accuracy, after batch 1020: 0.998168963938762\n",
      "Test set accuracy, after batch 1040: 0.9932353389959819\n",
      "Test set accuracy, after batch 1060: 0.98896292151976\n",
      "Test set accuracy, after batch 1080: 0.9990336198565688\n",
      "Test set accuracy, after batch 1100: 0.9998474136615635\n",
      "Test set accuracy, after batch 1120: 0.9996439652103148\n",
      "Test set accuracy, after batch 1140: 0.9999491378871879\n",
      "Test set accuracy, after batch 1160: 0.999694827323127\n",
      "Test set accuracy, after batch 1180: 0.9997965515487514\n",
      "Test set accuracy, after batch 1200: 0.9997965515487514\n",
      "Test set accuracy, after batch 1220: 0.9998474136615635\n",
      "Test set accuracy, after batch 1240: 0.9999491378871879\n",
      "Test set accuracy, after batch 1260: 1.0\n",
      "Test set accuracy, after batch 1280: 1.0\n",
      "Test set accuracy, after batch 1300: 1.0\n",
      "Test set accuracy, after batch 1320: 1.0\n",
      "Test set accuracy, after batch 1340: 1.0\n",
      "Test set accuracy, after batch 1360: 1.0\n",
      "Test set accuracy, after batch 1380: 0.9998982757743756\n",
      "Test set accuracy, after batch 1400: 1.0\n",
      "Test set accuracy, after batch 1420: 1.0\n",
      "Test set accuracy, after batch 1440: 1.0\n",
      "Test set accuracy, after batch 1460: 1.0\n",
      "Test set accuracy, after batch 1480: 1.0\n",
      "Test set accuracy, after batch 1500: 1.0\n",
      "Test set accuracy, after batch 1520: 1.0\n",
      "Test set accuracy, after batch 1540: 1.0\n",
      "Test set accuracy, after batch 1560: 1.0\n",
      "Test set accuracy, after batch 1580: 1.0\n",
      "Test set accuracy, after batch 1600: 1.0\n",
      "Test set accuracy, after batch 1620: 1.0\n",
      "Test set accuracy, after batch 1640: 1.0\n",
      "Test set accuracy, after batch 1660: 1.0\n",
      "Test set accuracy, after batch 1680: 1.0\n",
      "Test set accuracy, after batch 1700: 1.0\n",
      "Test set accuracy, after batch 1720: 1.0\n",
      "Test set accuracy, after batch 1740: 1.0\n",
      "Test set accuracy, after batch 1760: 1.0\n",
      "Test set accuracy, after batch 1780: 1.0\n",
      "Test set accuracy, after batch 1800: 1.0\n",
      "Test set accuracy, after batch 1820: 1.0\n",
      "Test set accuracy, after batch 1840: 1.0\n",
      "Test set accuracy, after batch 1860: 1.0\n",
      "Test set accuracy, after batch 1880: 1.0\n",
      "Test set accuracy, after batch 1900: 1.0\n",
      "Test set accuracy, after batch 1920: 1.0\n",
      "Test set accuracy, after batch 1940: 1.0\n",
      "Test set accuracy, after batch 1960: 1.0\n",
      "Test set accuracy, after batch 1980: 1.0\n",
      "Test set accuracy, after batch 2000: 1.0\n",
      "Test set accuracy, after batch 2020: 1.0\n",
      "Test set accuracy, after batch 2040: 1.0\n",
      "Test set accuracy, after batch 2060: 1.0\n",
      "Test set accuracy, after batch 2080: 1.0\n",
      "Test set accuracy, after batch 2100: 1.0\n",
      "Test set accuracy, after batch 2120: 1.0\n",
      "Test set accuracy, after batch 2140: 1.0\n",
      "Test set accuracy, after batch 2160: 1.0\n",
      "Test set accuracy, after batch 2180: 1.0\n",
      "Test set accuracy, after batch 2200: 1.0\n",
      "Test set accuracy, after batch 2220: 1.0\n",
      "Test set accuracy, after batch 2240: 1.0\n",
      "Test set accuracy, after batch 2260: 1.0\n",
      "Test set accuracy, after batch 2280: 1.0\n",
      "Test set accuracy, after batch 2300: 1.0\n",
      "Test set accuracy, after batch 2320: 1.0\n",
      "Test set accuracy, after batch 2340: 1.0\n",
      "Test set accuracy, after batch 2360: 1.0\n",
      "Test set accuracy, after batch 2380: 1.0\n",
      "Test set accuracy, after batch 2400: 1.0\n",
      "Test set accuracy, after batch 2420: 1.0\n",
      "Test set accuracy, after batch 2440: 1.0\n",
      "Test set accuracy, after batch 2460: 1.0\n",
      "Test set accuracy, after batch 2480: 1.0\n",
      "Test set accuracy, after batch 2500: 1.0\n",
      "Test set accuracy, after batch 2520: 1.0\n",
      "Test set accuracy, after batch 2540: 1.0\n",
      "Test set accuracy, after batch 2560: 1.0\n",
      "Test set accuracy, after batch 2580: 1.0\n",
      "Test set accuracy, after batch 2600: 1.0\n",
      "Test set accuracy, after batch 2620: 1.0\n",
      "Test set accuracy, after batch 2640: 1.0\n",
      "Test set accuracy, after batch 2660: 1.0\n",
      "Test set accuracy, after batch 2680: 1.0\n",
      "Test set accuracy, after batch 2700: 1.0\n",
      "Test set accuracy, after batch 2720: 1.0\n",
      "Test set accuracy, after batch 2740: 1.0\n",
      "Test set accuracy, after batch 2760: 1.0\n",
      "Test set accuracy, after batch 2780: 1.0\n",
      "Test set accuracy, after batch 2800: 1.0\n",
      "Test set accuracy, after batch 2820: 1.0\n",
      "Test set accuracy, after batch 2840: 1.0\n",
      "Test set accuracy, after batch 2860: 1.0\n"
     ]
    }
   ],
   "source": [
    "train(params, lambda model: between_m_n(model, 5, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps and Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool! It looks like the monotone quantifier is easier to learn than the non-monotone one.\n",
    "\n",
    "Here are some ideas for things that you can do to continue to develop your skills with these tools:\n",
    "\n",
    "1. Define more quantifiers, test them.\n",
    "2. Make sure the training data is balanced.\n",
    "3. Record data across trials, perform a statistical test to see whether one quantifier is learned faster than another.\n",
    "4. Parameterize the network architecture, instead of hard-coding it in `__init__`.\n",
    "5. Do a hyper-parameter search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
